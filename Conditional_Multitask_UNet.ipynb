{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e96ab56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Part 1: 기본 설정 및 라이브러리 임포트\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, Model, regularizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090c1459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# GPU가 사용 가능한지 확인\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c664a3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "# 데이터 전처리 함수 정의\n",
    "\n",
    "# --- 2-1. 이미지 로드 및 기본 전처리 ---\n",
    "def load_and_preprocess_image(path, size=(256, 256)):\n",
    "    img = Image.open(path).convert('L').resize(size, Image.LANCZOS)\n",
    "    return np.array(img, dtype=np.float32) / 255.0\n",
    "\n",
    "# --- 2-2. 데이터 증강 ---\n",
    "data_augmentation_pipeline = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.05),\n",
    "    layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "], name=\"geometric_augmentation\")\n",
    "\n",
    "def augment_brightness_contrast(image):\n",
    "    image_with_channel = image[..., tf.newaxis]\n",
    "    image_aug = tf.image.random_brightness(image_with_channel, max_delta=0.15)\n",
    "    image_aug = tf.image.random_contrast(image_aug, lower=0.8, upper=1.2)\n",
    "    return tf.squeeze(image_aug)\n",
    "\n",
    "# --- 2-3. 노이즈 추가 함수 ---\n",
    "def add_noise_snr_np(image, snr_db):\n",
    "    signal_power = np.mean(np.square(image))\n",
    "    snr_linear = 10 ** (snr_db / 10.0)\n",
    "    noise_power = signal_power / snr_linear\n",
    "    noise_sigma = np.sqrt(noise_power)\n",
    "    noise = np.random.normal(0, noise_sigma, image.shape).astype(np.float32)\n",
    "    return np.clip(image + noise, 0.0, 1.0).astype(np.float32)\n",
    "\n",
    "def add_salt_and_pepper_noise(image, amount=0.05):\n",
    "    noisy_image = np.copy(image)\n",
    "    # Salt\n",
    "    num_salt = np.ceil(amount * image.size * 0.5).astype(int)\n",
    "    coords = tuple(np.random.randint(0, i-1, num_salt) for i in image.shape if i > 1)\n",
    "    if coords and coords[0].size > 0: noisy_image[coords] = 1.0\n",
    "    # Pepper\n",
    "    num_pepper = np.ceil(amount * image.size * 0.5).astype(int)\n",
    "    coords = tuple(np.random.randint(0, i-1, num_pepper) for i in image.shape if i > 1)\n",
    "    if coords and coords[0].size > 0: noisy_image[coords] = 0.0\n",
    "    return noisy_image\n",
    "\n",
    "def add_burst_noise(image, burst_size_factor=0.2, intensity=0.8):\n",
    "    noisy_image = np.copy(image)\n",
    "    h, w = image.shape\n",
    "    burst_h, burst_w = int(h * burst_size_factor), int(w * burst_size_factor)\n",
    "    if h <= burst_h or w <= burst_w: return noisy_image\n",
    "    start_y = np.random.randint(0, h - burst_h)\n",
    "    start_x = np.random.randint(0, w - burst_w)\n",
    "    burst_noise = np.random.normal(0, intensity, (burst_h, burst_w)).astype(np.float32)\n",
    "    burst_area = noisy_image[start_y:start_y+burst_h, start_x:start_x+burst_w]\n",
    "    noisy_area = np.clip(burst_area + burst_noise, 0.0, 1.0)\n",
    "    noisy_image[start_y:start_y+burst_h, start_x:start_x+burst_w] = noisy_area\n",
    "    return noisy_image\n",
    "\n",
    "print(\"All preprocessing functions are defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e345c16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3: 파일 데이터 전처리 및 로드\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 3-1. 원본 이미지 경로 정의 및 로드 ---\n",
    "all_image_paths = ['data/mona_lisa.jpg'] + sorted(glob.glob('data/sample*.jpg'))\n",
    "class_names = [f\"Mona Lisa {i} ({'Original' if i==0 else f'Parody_{i}'})\" for i in range(len(all_image_paths))]\n",
    "try:\n",
    "    original_images = [load_and_preprocess_image(p) for p in all_image_paths]\n",
    "    print(f\"Successfully loaded {len(original_images)} images for {len(class_names)} classes.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during image loading: {e}\")\n",
    "\n",
    "# --- 3-2. 최종 데이터셋 생성 함수 (조건부 입력 포함) ---\n",
    "def create_conditional_dataset(images, samples_per_class=100, max_sigma=50.0):\n",
    "    X_noisy, X_noise_map, y_clean, y_class = [], [], [], []\n",
    "    noise_types = ['gaussian', 'salt_pepper', 'burst']\n",
    "    \n",
    "    with tqdm(total=len(images) * samples_per_class, desc=\"Generating Conditional Dataset\") as pbar:\n",
    "        for class_idx, original_image in enumerate(images):\n",
    "            for _ in range(samples_per_class):\n",
    "                # Augmentation\n",
    "                augmented_image = data_augmentation_pipeline(original_image[np.newaxis, ..., np.newaxis], training=True)\n",
    "                augmented_image = np.squeeze(augmented_image)\n",
    "                augmented_image = augment_brightness_contrast(augmented_image).numpy()\n",
    "                clean_augmented_image = np.clip(augmented_image, 0.0, 1.0)\n",
    "\n",
    "                # Noise Addition\n",
    "                noise_type = np.random.choice(noise_types)\n",
    "                sigma_equivalent = 0.0 # 노이즈 맵에 기록할 값\n",
    "                \n",
    "                if noise_type == 'gaussian':\n",
    "                    snr = np.random.choice([-10, -20, -30])\n",
    "                    # SNR을 sigma로 근사 변환 (단순화된 방식)\n",
    "                    signal_power = np.mean(np.square(clean_augmented_image))\n",
    "                    noise_power = signal_power / (10 ** (snr / 10.0))\n",
    "                    sigma_equivalent = np.sqrt(noise_power) * 255 # 0~255 스케일의 sigma\n",
    "                    noisy_img = add_noise_snr_np(clean_augmented_image, snr)\n",
    "                elif noise_type == 'salt_pepper':\n",
    "                    amount = np.random.uniform(0.05, 0.2)\n",
    "                    noisy_img = add_salt_and_pepper_noise(clean_augmented_image, amount=amount)\n",
    "                    sigma_equivalent = amount * 50 # S&P 강도를 sigma처럼 맵핑 (경험적)\n",
    "                else: # burst\n",
    "                    size = np.random.uniform(0.2, 0.5)\n",
    "                    intensity = np.random.uniform(0.7, 1.0)\n",
    "                    noisy_img = add_burst_noise(clean_augmented_image, burst_size_factor=size, intensity=intensity)\n",
    "                    sigma_equivalent = size * 50 # Burst 강도를 sigma처럼 맵핑 (경험적)\n",
    "\n",
    "                # Noise Map 생성\n",
    "                noise_map = np.full(clean_augmented_image.shape, sigma_equivalent / max_sigma, dtype=np.float32)\n",
    "                \n",
    "                X_noisy.append(noisy_img)\n",
    "                X_noise_map.append(noise_map)\n",
    "                y_clean.append(clean_augmented_image)\n",
    "                y_class.append(class_idx)\n",
    "                pbar.update(1)\n",
    "\n",
    "    indices = np.arange(len(X_noisy))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    X_noisy = np.array(X_noisy)[indices][..., np.newaxis]\n",
    "    X_noise_map = np.array(X_noise_map)[indices][..., np.newaxis]\n",
    "    y_clean = np.array(y_clean)[indices][..., np.newaxis]\n",
    "    y_class = np.array(y_class)[indices]\n",
    "    \n",
    "    return [X_noisy, X_noise_map], [y_clean, y_class]\n",
    "\n",
    "# --- 3-3. 데이터셋 생성 실행 ---\n",
    "[X_noisy_data, X_noise_map_data], [y_restore_data, y_classify_data] = create_conditional_dataset(\n",
    "    original_images, samples_per_class=100\n",
    ")\n",
    "\n",
    "print(\"\\n--- Dataset Creation Complete ---\")\n",
    "print(f\"Input Noisy Image Shape: {X_noisy_data.shape}\")\n",
    "print(f\"Input Noise Map Shape: {X_noise_map_data.shape}\")\n",
    "print(f\"Target Clean Image Shape: {y_restore_data.shape}\")\n",
    "print(f\"Target Class Label Shape: {y_classify_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064d98e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_conditional_multitask_unet(input_shape, num_classes):\n",
    "    \n",
    "    def conv_block(input_tensor, num_filters):\n",
    "        x = layers.Conv2D(num_filters, 3, padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(1e-5))(input_tensor)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        x = layers.Conv2D(num_filters, 3, padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(1e-5))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        return x\n",
    "\n",
    "    def decoder_block(input_tensor, skip_tensor, num_filters):\n",
    "        x = layers.Conv2DTranspose(num_filters, 2, strides=2, padding='same')(input_tensor)\n",
    "        x = layers.concatenate([x, skip_tensor])\n",
    "        x = conv_block(x, num_filters)\n",
    "        return x\n",
    "\n",
    "    # --- 두 개의 입력 정의 ---\n",
    "    image_input = layers.Input(shape=input_shape, name=\"image_input\")\n",
    "    noise_map_input = layers.Input(shape=input_shape, name=\"noise_map_input\")\n",
    "    \n",
    "    # --- 입력 결합 ---\n",
    "    concatenated_input = layers.concatenate([image_input, noise_map_input]) # Shape: (H, W, 2)\n",
    "    \n",
    "    # Encoder\n",
    "    c1 = conv_block(concatenated_input, 16)\n",
    "    p1 = layers.MaxPooling2D(2)(c1)\n",
    "    c2 = conv_block(p1, 32)\n",
    "    p2 = layers.MaxPooling2D(2)(c2)\n",
    "    c3 = conv_block(p2, 64)\n",
    "    p3 = layers.MaxPooling2D(2)(c3)\n",
    "    \n",
    "    # Bottleneck\n",
    "    b = conv_block(p3, 128)\n",
    "    \n",
    "    # Decoder\n",
    "    d3 = decoder_block(b, c3, 64)   \n",
    "    d2 = decoder_block(d3, c2, 32)\n",
    "    d1 = decoder_block(d2, c1, 16)\n",
    "    \n",
    "    # --- 두 개의 헤드 정의 ---\n",
    "    restoration_head = layers.Conv2D(1, 1, activation='sigmoid', name=\"restoration_output\")(d1)\n",
    "    \n",
    "    flat = layers.GlobalAveragePooling2D()(b)\n",
    "    dense1 = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(flat)\n",
    "    dropout = layers.Dropout(0.5)(dense1)\n",
    "    classification_head = layers.Dense(num_classes, activation='softmax', name=\"classification_output\")(dropout)\n",
    "    \n",
    "    model = Model(inputs=[image_input, noise_map_input], outputs=[restoration_head, classification_head])\n",
    "    return model\n",
    "\n",
    "# 모델 생성\n",
    "num_total_classes = len(class_names)\n",
    "model = build_conditional_multitask_unet(input_shape=(256, 256, 1), num_classes=num_total_classes)\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
