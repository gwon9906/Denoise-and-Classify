{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: 모델 임포트 및 Sequential 모델 학습\n",
    "\n",
    "이 노트북은 Part 1에서 이어집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 필수 라이브러리 임포트 및 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필수 라이브러리 임포트\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# 학습 파라미터 정의 (Part 1에서 정의했지만 여기서도 명시)\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 128\n",
    "VALIDATION_SPLIT = 0.2\n",
    "INITIAL_LR = 1e-3\n",
    "FINAL_LR = INITIAL_LR * 0.1\n",
    "DECAY_RATE = (FINAL_LR / INITIAL_LR) ** (1 / EPOCHS)\n",
    "\n",
    "print(f\"✓ Libraries imported\")\n",
    "print(f\"✓ Training configuration:\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Initial LR: {INITIAL_LR}\")\n",
    "print(f\"  Final LR: {FINAL_LR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 유틸리티 함수 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유틸리티 함수 임포트\n",
    "from utils import (\n",
    "    get_callbacks,\n",
    "    clear_memory,\n",
    "    save_history,\n",
    "    save_results\n",
    ")\n",
    "\n",
    "# 디렉토리 생성\n",
    "os.makedirs('weights', exist_ok=True)\n",
    "os.makedirs('history', exist_ok=True)\n",
    "os.makedirs('results', exist_ok=True)\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "\n",
    "print(\"✓ Utility functions loaded\")\n",
    "print(\"✓ Directories created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "print(\"Loading augmented data...\")\n",
    "x_train_augmented = np.load('data/x_train_augmented.npy')\n",
    "y_train_augmented = np.load('data/y_train_augmented.npy')\n",
    "x_train_clean = np.load('data/x_train_clean.npy')\n",
    "\n",
    "# Test data\n",
    "x_test_augmented = np.load('data/x_test_augmented.npy')\n",
    "y_test_augmented = np.load('data/y_test_augmented.npy')\n",
    "x_test_clean = np.load('data/x_test_clean.npy')\n",
    "\n",
    "print(f\"✓ Train shape: {x_train_augmented.shape}\")\n",
    "print(f\"✓ Test shape: {x_test_augmented.shape}\")\n",
    "\n",
    "# BAM 모델용 flattened 데이터\n",
    "x_train_flat = x_train_augmented.reshape(x_train_augmented.shape[0], -1)\n",
    "x_train_clean_flat = np.repeat(x_train_clean, 3, axis=0).reshape(-1, 32*32*3)\n",
    "\n",
    "x_test_flat = x_test_augmented.reshape(x_test_augmented.shape[0], -1)\n",
    "x_test_clean_flat = np.repeat(x_test_clean, 3, axis=0).reshape(-1, 32*32*3)\n",
    "\n",
    "print(f\"✓ Train flat shape: {x_train_flat.shape}\")\n",
    "print(f\"✓ Test flat shape: {x_test_flat.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 모델 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 임포트 (프로젝트 루트에서)\n",
    "from bam_sequential import SequentialBAM\n",
    "\n",
    "# 다른 모델들 (있다면)\n",
    "try:\n",
    "    from cae_sequential import SequentialCAE\n",
    "    print(\"✓ Sequential CAE imported\")\n",
    "except:\n",
    "    print(\"⚠ Sequential CAE not found (optional)\")\n",
    "\n",
    "try:\n",
    "    from unet_sequential import SequentialUNet\n",
    "    print(\"✓ Sequential U-Net imported\")\n",
    "except:\n",
    "    print(\"⚠ Sequential U-Net not found (optional)\")\n",
    "\n",
    "print(\"\\n✓ BAM model imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 학습 시작 - Sequential BAM\n",
    "\n",
    "### 9.1 Sequential BAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Model 1/3: Sequential BAM\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 모델 생성\n",
    "seq_bam = SequentialBAM(\n",
    "    input_dim=3072,  # 32*32*3\n",
    "    denoise_latent=256,\n",
    "    cls_latent=128,\n",
    "    num_classes=10\n",
    ")\n",
    "\n",
    "# 모델 컴파일\n",
    "seq_bam.compile_models(\n",
    "    denoise_lr=INITIAL_LR,\n",
    "    cls_lr=INITIAL_LR\n",
    ")\n",
    "\n",
    "print(\"\\n[Stage 1: Denoising BAM]\")\n",
    "seq_bam.denoise_model.summary()\n",
    "\n",
    "# Stage 1 학습\n",
    "callbacks_stage1 = get_callbacks(\n",
    "    'sequential_bam_stage1', \n",
    "    monitor='val_mse', \n",
    "    patience=30,\n",
    "    initial_lr=INITIAL_LR,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "history_stage1 = seq_bam.train_stage1(\n",
    "    x_train_flat,\n",
    "    x_train_clean_flat,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    callbacks=callbacks_stage1\n",
    ")\n",
    "\n",
    "# Stage 1 결과 저장\n",
    "save_history(history_stage1, 'sequential_bam_stage1')\n",
    "seq_bam.denoise_model.save('weights/sequential_bam_denoise.keras')\n",
    "print(\"✓ Stage 1 model saved\")\n",
    "\n",
    "print(\"\\n[Stage 2: Classification BAM]\")\n",
    "seq_bam.cls_model.summary()\n",
    "\n",
    "# Stage 2 학습\n",
    "callbacks_stage2 = get_callbacks(\n",
    "    'sequential_bam_stage2', \n",
    "    monitor='val_accuracy', \n",
    "    patience=30,\n",
    "    initial_lr=INITIAL_LR,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "history_stage2 = seq_bam.train_stage2(\n",
    "    x_train_flat,\n",
    "    y_train_augmented,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    callbacks=callbacks_stage2\n",
    ")\n",
    "\n",
    "# Stage 2 결과 저장\n",
    "save_history(history_stage2, 'sequential_bam_stage2')\n",
    "seq_bam.cls_model.save('weights/sequential_bam_classification.keras')\n",
    "print(\"✓ Stage 2 model saved\")\n",
    "\n",
    "# 평가\n",
    "print(\"\\n[Evaluation]\")\n",
    "results = seq_bam.evaluate(\n",
    "    x_test_flat, \n",
    "    x_test_clean_flat, \n",
    "    y_test_augmented, \n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "save_results(results, 'sequential_bam')\n",
    "\n",
    "print(\"\\nSequential BAM Results:\")\n",
    "print(f\"  Restoration MSE: {results['restoration']['mse']:.6f}\")\n",
    "print(f\"  Restoration PSNR: {results['restoration']['psnr']:.2f} dB\")\n",
    "print(f\"  Classification Accuracy: {results['classification']['accuracy']:.4f}\")\n",
    "\n",
    "# 메모리 정리\n",
    "del seq_bam\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Sequential CAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Model 2/6: Sequential CAE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 모델 생성\n",
    "seq_cae = SequentialCAE(\n",
    "    input_shape=(32, 32, 3),\n",
    "    num_classes=10\n",
    ")\n",
    "\n",
    "# 모델 컴파일\n",
    "seq_cae.compile_models(\n",
    "    restore_lr=INITIAL_LR,\n",
    "    cls_lr=INITIAL_LR,\n",
    "    restore_loss='mae'\n",
    ")\n",
    "\n",
    "print(\"\\n[Stage 1: Restoration CAE]\")\n",
    "seq_cae.restore_model.summary()\n",
    "\n",
    "# Stage 1 학습\n",
    "callbacks_stage1 = get_callbacks('sequential_cae_stage1', monitor='val_mae', patience=30)\n",
    "history_stage1 = seq_cae.train_stage1(\n",
    "    x_train_augmented,\n",
    "    np.repeat(x_train_clean, 3, axis=0),  # 원본 데이터 3배 복제\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    callbacks=callbacks_stage1\n",
    ")\n",
    "\n",
    "# Stage 1 결과 저장\n",
    "save_history(history_stage1, 'sequential_cae_stage1')\n",
    "seq_cae.restore_model.save('weights/sequential_cae_restore.keras')\n",
    "print(\"✓ Stage 1 model saved\")\n",
    "\n",
    "print(\"\\n[Stage 2: Classification CAE]\")\n",
    "seq_cae.cls_model.summary()\n",
    "\n",
    "# Stage 2 학습\n",
    "callbacks_stage2 = get_callbacks('sequential_cae_stage2', monitor='val_accuracy', patience=30)\n",
    "history_stage2 = seq_cae.train_stage2(\n",
    "    x_train_augmented,\n",
    "    y_train_augmented,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    callbacks=callbacks_stage2\n",
    ")\n",
    "\n",
    "# Stage 2 결과 저장\n",
    "save_history(history_stage2, 'sequential_cae_stage2')\n",
    "seq_cae.cls_model.save('weights/sequential_cae_classification.keras')\n",
    "print(\"✓ Stage 2 model saved\")\n",
    "\n",
    "# 평가\n",
    "print(\"\\n[Evaluation]\")\n",
    "results = seq_cae.evaluate(\n",
    "    x_test_augmented,\n",
    "    np.repeat(x_test_clean, 3, axis=0),\n",
    "    y_test_augmented,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "save_results(results, 'sequential_cae')\n",
    "\n",
    "print(\"\\nSequential CAE Results:\")\n",
    "print(f\"  Restoration MSE: {results['restoration']['mse']:.6f}\")\n",
    "print(f\"  Restoration PSNR: {results['restoration']['psnr']:.2f} dB\")\n",
    "print(f\"  Classification Accuracy: {results['classification']['accuracy']:.4f}\")\n",
    "\n",
    "# 메모리 정리\n",
    "del seq_cae\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Sequential U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Model 3/6: Sequential U-Net\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 모델 생성\n",
    "seq_unet = SequentialUNet(\n",
    "    input_shape=(32, 32, 3),\n",
    "    num_classes=10,\n",
    "    restore_dropout=0.0,\n",
    "    cls_dropout=0.1\n",
    ")\n",
    "\n",
    "# 모델 컴파일\n",
    "seq_unet.compile_models(\n",
    "    restore_lr=INITIAL_LR,\n",
    "    cls_lr=INITIAL_LR,\n",
    "    restore_loss='mae'\n",
    ")\n",
    "\n",
    "print(\"\\n[Stage 1: Restoration U-Net]\")\n",
    "seq_unet.restore_model.summary()\n",
    "\n",
    "# Stage 1 학습\n",
    "callbacks_stage1 = get_callbacks('sequential_unet_stage1', monitor='val_mae', patience=30)\n",
    "history_stage1 = seq_unet.train_stage1(\n",
    "    x_train_augmented,\n",
    "    np.repeat(x_train_clean, 3, axis=0),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    callbacks=callbacks_stage1\n",
    ")\n",
    "\n",
    "# Stage 1 결과 저장\n",
    "save_history(history_stage1, 'sequential_unet_stage1')\n",
    "seq_unet.restore_model.save('weights/sequential_unet_restore.keras')\n",
    "print(\"✓ Stage 1 model saved\")\n",
    "\n",
    "print(\"\\n[Stage 2: Classification U-Net]\")\n",
    "seq_unet.cls_model.summary()\n",
    "\n",
    "# Stage 2 학습\n",
    "callbacks_stage2 = get_callbacks('sequential_unet_stage2', monitor='val_accuracy', patience=30)\n",
    "history_stage2 = seq_unet.train_stage2(\n",
    "    x_train_augmented,\n",
    "    y_train_augmented,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    callbacks=callbacks_stage2\n",
    ")\n",
    "\n",
    "# Stage 2 결과 저장\n",
    "save_history(history_stage2, 'sequential_unet_stage2')\n",
    "seq_unet.cls_model.save('weights/sequential_unet_classification.keras')\n",
    "print(\"✓ Stage 2 model saved\")\n",
    "\n",
    "# 평가\n",
    "print(\"\\n[Evaluation]\")\n",
    "results = seq_unet.evaluate(\n",
    "    x_test_augmented,\n",
    "    np.repeat(x_test_clean, 3, axis=0),\n",
    "    y_test_augmented,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "save_results(results, 'sequential_unet')\n",
    "\n",
    "print(\"\\nSequential U-Net Results:\")\n",
    "print(f\"  Restoration MSE: {results['restoration']['mse']:.6f}\")\n",
    "print(f\"  Restoration PSNR: {results['restoration']['psnr']:.2f} dB\")\n",
    "print(f\"  Classification Accuracy: {results['classification']['accuracy']:.4f}\")\n",
    "\n",
    "# 메모리 정리\n",
    "del seq_unet\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sequential 모델 학습 완료\n",
    "\n",
    "3개의 Sequential 모델 학습이 완료되었습니다.\n",
    "\n",
    "다음 Part 3에서 MTL 모델들을 학습하겠습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
