{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow: 2.15.0\n",
            "GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "# Lightweight SNRâ€“SER comparison (load UNet, train CAE/DnCNN)\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers, Model, regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "\n",
        "print(\"TensorFlow:\", tf.__version__)\n",
        "print(\"GPU:\", tf.config.list_physical_devices('GPU'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-13 15:30:34.285574: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4\n",
            "2025-10-13 15:30:34.285594: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
            "2025-10-13 15:30:34.285600: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
            "2025-10-13 15:30:34.285628: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2025-10-13 15:30:34.285644: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data ready: (50000, 32, 32, 3) (10000, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "# Data: CIFAR-10 and z-score helpers\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "x_train = x_train.astype('float32')/255.0; y_train = y_train.flatten()\n",
        "x_test  = x_test.astype('float32')/255.0;  y_test  = y_test.flatten()\n",
        "\n",
        "MEAN = tf.constant(np.mean(x_train, axis=(0,1,2)), dtype=tf.float32)\n",
        "STD  = tf.constant(np.std(x_train,  axis=(0,1,2)) + 1e-6, dtype=tf.float32)\n",
        "\n",
        "def to_zscore(x):\n",
        "    return (x - MEAN) / STD\n",
        "\n",
        "def from_zscore(z):\n",
        "    return z * STD + MEAN\n",
        "\n",
        "cifar10_class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
        "print('Data ready:', x_train.shape, x_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Noise: fixed SNR generators (Gaussian/S&P/Burst)\n",
        "\n",
        "def gaussian_snr_to_cond_vector(snr_db) -> tf.Tensor:\n",
        "    # Fully TF-native: accept tensor or float\n",
        "    snr_db = tf.cast(snr_db, tf.float32)\n",
        "    log10_sigma = -snr_db / 20.0\n",
        "    c = tf.clip_by_value(log10_sigma - 0.5, 0.0, 1.0)\n",
        "    return tf.stack([tf.constant(1.0), tf.constant(0.0), tf.constant(0.0), c])\n",
        "\n",
        "\n",
        "def add_gaussian_noise_fixed_snr(clean_img_01: tf.Tensor, snr_db):\n",
        "    img_z = to_zscore(clean_img_01)\n",
        "    snr_db = tf.cast(snr_db, tf.float32)\n",
        "    sigma = tf.pow(10.0, -snr_db/20.0)\n",
        "    noise = tf.random.normal(tf.shape(img_z), stddev=sigma, dtype=tf.float32)\n",
        "    noisy_z = img_z + noise\n",
        "    cond = gaussian_snr_to_cond_vector(snr_db)\n",
        "    return noisy_z, cond\n",
        "\n",
        "\n",
        "def snr_scale_noise(clean_z: tf.Tensor, noisy_z: tf.Tensor, target_snr_db: tf.Tensor):\n",
        "    noise = noisy_z - clean_z\n",
        "    px = tf.reduce_mean(tf.square(clean_z))\n",
        "    pn = tf.reduce_mean(tf.square(noise)) + 1e-12\n",
        "    r = tf.pow(10.0, target_snr_db/10.0)\n",
        "    pn_target = px / r\n",
        "    k = tf.sqrt(tf.maximum(pn_target / pn, 1e-12))\n",
        "    return clean_z + k*noise\n",
        "\n",
        "\n",
        "def add_sp_noise_fixed_snr(clean_img_01: tf.Tensor, snr_db: tf.Tensor, amount: float = 0.15):\n",
        "    img_z = to_zscore(clean_img_01)\n",
        "    u = tf.random.uniform(tf.shape(img_z))\n",
        "    salt = tf.cast(u < amount*0.5, tf.float32)\n",
        "    pepper = tf.cast(u > 1.0 - amount*0.5, tf.float32)\n",
        "    noisy_z = img_z * (1.0 - salt - pepper) + salt\n",
        "    noisy_z = snr_scale_noise(img_z, noisy_z, snr_db)\n",
        "    return noisy_z, tf.convert_to_tensor([0.0,1.0,0.0,amount], dtype=tf.float32)\n",
        "\n",
        "\n",
        "def add_burst_noise_fixed_snr(clean_img_01: tf.Tensor, snr_db: tf.Tensor, size_factor: float = 0.3, intensity: float = 0.85):\n",
        "    img_z = to_zscore(clean_img_01)\n",
        "    h = tf.shape(img_z)[0]; w = tf.shape(img_z)[1]; cch = tf.shape(img_z)[2]\n",
        "    bh = tf.maximum(1, tf.cast(tf.cast(h, tf.float32)*size_factor, tf.int32))\n",
        "    bw = tf.maximum(1, tf.cast(tf.cast(w, tf.float32)*size_factor, tf.int32))\n",
        "    sy = tf.random.uniform([], maxval=tf.maximum(1, h-bh), dtype=tf.int32)\n",
        "    sx = tf.random.uniform([], maxval=tf.maximum(1, w-bw), dtype=tf.int32)\n",
        "    patch = tf.random.normal([bh, bw, cch], stddev=intensity)\n",
        "    noise = tf.pad(patch, [[sy, h-sy-bh], [sx, w-sx-bw], [0,0]])\n",
        "    mask  = tf.pad(tf.ones([bh, bw, cch]), [[sy, h-sy-bh], [sx, w-sx-bw], [0,0]])\n",
        "    noisy_z = img_z * (1.0 - mask) + (img_z + noise) * mask\n",
        "    noisy_z = snr_scale_noise(img_z, noisy_z, snr_db)\n",
        "    c = tf.clip_by_value(size_factor*intensity, 0.0, 1.0)\n",
        "    return noisy_z, tf.convert_to_tensor([0.0,0.0,1.0,c], dtype=tf.float32)\n",
        "\n",
        "\n",
        "def make_fixed_snr_dataset_noise(x, y, snr_db: float, noise_type: str = 'gaussian', batch_size: int = 128):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "    def _map_fn(clean_img, label):\n",
        "        clean_img = tf.cast(clean_img, tf.float32)\n",
        "        sdb = tf.cast(snr_db, tf.float32)\n",
        "        if noise_type == 'gaussian': noisy_z, cond = add_gaussian_noise_fixed_snr(clean_img, sdb)\n",
        "        elif noise_type in ('sp','s&p'): noisy_z, cond = add_sp_noise_fixed_snr(clean_img, sdb)\n",
        "        elif noise_type == 'burst': noisy_z, cond = add_burst_noise_fixed_snr(clean_img, sdb)\n",
        "        else: raise ValueError(noise_type)\n",
        "        clean_z = to_zscore(clean_img)\n",
        "        return (noisy_z, cond), (clean_z, label)\n",
        "    return ds.map(_map_fn, num_parallel_calls=tf.data.AUTOTUNE).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded UNet from: /Users/ihaegwon/Lab/best_cifar10_conditional_model.keras\n",
            "UNet inputs: ['image_input', 'noise_map_input']\n"
          ]
        }
      ],
      "source": [
        "# Load pretrained UNet (conditional multitask UNet)\n",
        "unet_path = '/Users/ihaegwon/Lab/best_cifar10_conditional_model.keras'\n",
        "unet_model = tf.keras.models.load_model(unet_path)\n",
        "print('Loaded UNet from:', unet_path)\n",
        "print('UNet inputs:', [inp.name for inp in unet_model.inputs])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CAE/DnCNN ready with LR schedule\n"
          ]
        }
      ],
      "source": [
        "# CAE/DnCNN multitask models\n",
        "\n",
        "def build_cae_multitask(input_shape_img=(32,32,3), input_shape_map=(4,), num_classes=10):\n",
        "    img_in  = layers.Input(shape=input_shape_img, name='image_input')\n",
        "    cond_in = layers.Input(shape=input_shape_map, name='noise_map_input')\n",
        "    x = layers.Conv2D(32,3,padding='same',activation='relu')(img_in)\n",
        "    x = layers.Conv2D(32,3,padding='same',activation='relu')(x)\n",
        "    s1 = x  # 32x32\n",
        "    p1 = layers.MaxPooling2D(2)(s1)  # 16x16\n",
        "    x = layers.Conv2D(64,3,padding='same',activation='relu')(p1)\n",
        "    x = layers.Conv2D(64,3,padding='same',activation='relu')(x)\n",
        "    s2 = x  # 16x16\n",
        "    p2 = layers.MaxPooling2D(2)(s2)  # 8x8\n",
        "    x = layers.Conv2D(128,3,padding='same',activation='relu')(p2)\n",
        "    x = layers.Conv2D(128,3,padding='same',activation='relu')(x)\n",
        "    feat = layers.GlobalAveragePooling2D()(x)\n",
        "    feat = layers.Concatenate()([feat, cond_in])\n",
        "    feat = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(feat)\n",
        "    feat = layers.Dropout(0.5)(feat)\n",
        "    cls_out = layers.Dense(num_classes, activation='softmax', name='classification_output')(feat)\n",
        "    d = layers.Conv2DTranspose(64,2,strides=2,padding='same')(x)  # 16x16\n",
        "    d = layers.Concatenate()([d, s2])\n",
        "    d = layers.Conv2D(64,3,padding='same',activation='relu')(d)\n",
        "    d = layers.Conv2D(64,3,padding='same',activation='relu')(d)\n",
        "    d = layers.Conv2DTranspose(32,2,strides=2,padding='same')(d)  # 32x32\n",
        "    d = layers.Concatenate()([d, s1])\n",
        "    d = layers.Conv2D(32,3,padding='same',activation='relu')(d)\n",
        "    d = layers.Conv2D(32,3,padding='same',activation='relu')(d)\n",
        "    rec = layers.Conv2D(3,1,activation='linear', name='restoration_output')(d)\n",
        "    return Model(inputs=[img_in, cond_in], outputs=[rec, cls_out], name='CAE_multitask')\n",
        "\n",
        "\n",
        "def build_dncnn_multitask(input_shape_img=(32,32,3), input_shape_map=(4,), num_classes=10, depth=17, filters=64):\n",
        "    img_in  = layers.Input(shape=input_shape_img, name='image_input')\n",
        "    cond_in = layers.Input(shape=input_shape_map, name='noise_map_input')\n",
        "    x = layers.Conv2D(filters,3,padding='same',activation='relu')(img_in)\n",
        "    for _ in range(depth-2):\n",
        "        x = layers.Conv2D(filters,3,padding='same',use_bias=False)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation('relu')(x)\n",
        "    res = layers.Conv2D(3,3,padding='same',activation='linear', name='residual_pred')(x)\n",
        "    rec = layers.Subtract(name='restoration_output')([img_in, res])\n",
        "    feat = layers.GlobalAveragePooling2D()(x)\n",
        "    feat = layers.Concatenate()([feat, cond_in])\n",
        "    feat = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(feat)\n",
        "    feat = layers.Dropout(0.5)(feat)\n",
        "    cls_out = layers.Dense(num_classes, activation='softmax', name='classification_output')(feat)\n",
        "    return Model(inputs=[img_in, cond_in], outputs=[rec, cls_out], name='DnCNN_multitask')\n",
        "\n",
        "# Learning rate schedule (match UNet): ExponentialDecay per-step\n",
        "STEPS_PER_EPOCH = int(np.ceil(len(x_train)/128))\n",
        "initial_learning_rate = 1e-4\n",
        "lr_schedule = ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=STEPS_PER_EPOCH,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True\n",
        ")\n",
        "\n",
        "cae_model = build_cae_multitask(num_classes=10)\n",
        "dncnn_model = build_dncnn_multitask(num_classes=10)\n",
        "\n",
        "for m in [cae_model, dncnn_model]:\n",
        "    m.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "              loss={'restoration_output':'mae','classification_output':'sparse_categorical_crossentropy'},\n",
        "              loss_weights={'restoration_output':0.8,'classification_output':0.2},\n",
        "              metrics={'classification_output':'accuracy'})\n",
        "\n",
        "print('CAE/DnCNN ready with LR schedule')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datasets ready\n"
          ]
        }
      ],
      "source": [
        "# Mixed-SNR training dataset (Gaussian only by default)\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "def gen_mixed_gaussian_sample(clean_img, label):\n",
        "    clean_img = tf.cast(clean_img, tf.float32)\n",
        "    snr_db = tf.random.uniform([], -30.0, -10.0)\n",
        "    noisy_z, cond = add_gaussian_noise_fixed_snr(clean_img, snr_db)\n",
        "    clean_z = to_zscore(clean_img)\n",
        "    return (noisy_z, cond), (clean_z, label)\n",
        "\n",
        "train_ds_mixed = (tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "                  .shuffle(50000)\n",
        "                  .map(gen_mixed_gaussian_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "                  .batch(BATCH_SIZE)\n",
        "                  .prefetch(tf.data.AUTOTUNE))\n",
        "\n",
        "val_ds_mixed = (tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "                .map(gen_mixed_gaussian_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "                .batch(BATCH_SIZE)\n",
        "                .prefetch(tf.data.AUTOTUNE))\n",
        "\n",
        "print('Datasets ready')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# SER evaluators and plotting\n",
        "\n",
        "def eval_model_ser_over_snrs(model, x, y, snr_list_db, noise_type='gaussian', batch_size=512):\n",
        "    results = {}\n",
        "    for snr in snr_list_db:\n",
        "        ds = make_fixed_snr_dataset_noise(x, y, snr_db=float(snr), noise_type=noise_type, batch_size=batch_size)\n",
        "        total = 0; errors = 0\n",
        "        for (noisy_z_b, cond_b), (clean_z_b, label_b) in ds:\n",
        "            _, logits_b = model.predict([noisy_z_b, cond_b], verbose=0)\n",
        "            pred = np.argmax(logits_b, axis=-1)\n",
        "            total += label_b.shape[0]\n",
        "            errors += int(np.sum(pred != label_b.numpy()))\n",
        "        results[float(snr)] = errors / max(1, total)\n",
        "    return results\n",
        "\n",
        "\n",
        "def plot_snr_ser(models_ser_dict, title='SNR vs SER', threshold=0.10):\n",
        "    plt.figure(figsize=(7,5))\n",
        "    for name, ser_map in models_ser_dict.items():\n",
        "        snrs = np.array(sorted(ser_map.keys()))\n",
        "        sers = np.array([ser_map[s] for s in snrs])\n",
        "        plt.plot(snrs, sers, marker='o', label=name)\n",
        "        idx = np.where(np.diff((sers <= threshold).astype(int)) != 0)[0]\n",
        "        if idx.size > 0:\n",
        "            i = idx[0]\n",
        "            x0,x1 = snrs[i], snrs[i+1]; y0,y1 = sers[i], sers[i+1]\n",
        "            if y1 != y0:\n",
        "                x_cross = x0 + (threshold - y0) * (x1 - x0) / (y1 - y0)\n",
        "                plt.scatter([x_cross],[threshold], marker='x', s=80)\n",
        "                plt.text(x_cross, threshold+0.02, f\"{name}: {x_cross:.1f} dB\", ha='center', fontsize=9)\n",
        "    plt.axhline(threshold, color='gray', ls='--', lw=1, label='SER=0.10')\n",
        "    plt.ylim(0,1); plt.xlabel('SNR (dB)'); plt.ylabel('SER'); plt.title(title); plt.grid(ls=':'); plt.legend(); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate UNet SER first (Gaussian)\n",
        "snr_grid = list(range(-30, -9, 2))\n",
        "unet_ser = eval_model_ser_over_snrs(unet_model, x_test, y_test, snr_grid, noise_type='gaussian', batch_size=512)\n",
        "print('UNet SER computed for', len(snr_grid), 'SNR points')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training CAE (up to 200 epochs, early-stop) ...\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-13 15:30:40.806612: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
            "2025-10-13 15:30:40.892496: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 27s 65ms/step - loss: 1.0490 - restoration_output_loss: 0.7133 - classification_output_loss: 2.3340 - classification_output_accuracy: 0.1214 - val_loss: 0.9621 - val_restoration_output_loss: 0.6325 - val_classification_output_loss: 2.2282 - val_classification_output_accuracy: 0.1773\n",
            "Epoch 2/200\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 0.9540 - restoration_output_loss: 0.6116 - classification_output_loss: 2.2742 - classification_output_accuracy: 0.1593 - val_loss: 0.9202 - val_restoration_output_loss: 0.5978 - val_classification_output_loss: 2.1630 - val_classification_output_accuracy: 0.2105\n",
            "Epoch 3/200\n",
            "391/391 [==============================] - 22s 57ms/step - loss: 0.9299 - restoration_output_loss: 0.5910 - classification_output_loss: 2.2409 - classification_output_accuracy: 0.1743 - val_loss: 0.9039 - val_restoration_output_loss: 0.5835 - val_classification_output_loss: 2.1425 - val_classification_output_accuracy: 0.2176\n",
            "Epoch 4/200\n",
            "391/391 [==============================] - 21s 55ms/step - loss: 0.9185 - restoration_output_loss: 0.5816 - classification_output_loss: 2.2243 - classification_output_accuracy: 0.1840 - val_loss: 0.8964 - val_restoration_output_loss: 0.5790 - val_classification_output_loss: 2.1258 - val_classification_output_accuracy: 0.2227\n",
            "Epoch 5/200\n",
            "391/391 [==============================] - 22s 55ms/step - loss: 0.9125 - restoration_output_loss: 0.5762 - classification_output_loss: 2.2183 - classification_output_accuracy: 0.1896 - val_loss: 0.8891 - val_restoration_output_loss: 0.5747 - val_classification_output_loss: 2.1083 - val_classification_output_accuracy: 0.2323\n",
            "Epoch 6/200\n",
            "391/391 [==============================] - 22s 57ms/step - loss: 0.9096 - restoration_output_loss: 0.5738 - classification_output_loss: 2.2146 - classification_output_accuracy: 0.1959 - val_loss: 0.8888 - val_restoration_output_loss: 0.5763 - val_classification_output_loss: 2.1017 - val_classification_output_accuracy: 0.2331\n",
            "Epoch 7/200\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.9045 - restoration_output_loss: 0.5715 - classification_output_loss: 2.2000 - classification_output_accuracy: 0.1981 - val_loss: 0.8837 - val_restoration_output_loss: 0.5727 - val_classification_output_loss: 2.0922 - val_classification_output_accuracy: 0.2360\n",
            "Epoch 8/200\n",
            "391/391 [==============================] - 22s 56ms/step - loss: 0.9013 - restoration_output_loss: 0.5689 - classification_output_loss: 2.1958 - classification_output_accuracy: 0.2031 - val_loss: 0.8788 - val_restoration_output_loss: 0.5679 - val_classification_output_loss: 2.0878 - val_classification_output_accuracy: 0.2404\n",
            "Epoch 9/200\n",
            "391/391 [==============================] - 25s 63ms/step - loss: 0.8992 - restoration_output_loss: 0.5676 - classification_output_loss: 2.1916 - classification_output_accuracy: 0.2037 - val_loss: 0.8751 - val_restoration_output_loss: 0.5652 - val_classification_output_loss: 2.0810 - val_classification_output_accuracy: 0.2404\n",
            "Epoch 10/200\n",
            "391/391 [==============================] - 24s 62ms/step - loss: 0.8971 - restoration_output_loss: 0.5673 - classification_output_loss: 2.1833 - classification_output_accuracy: 0.2119 - val_loss: 0.8732 - val_restoration_output_loss: 0.5648 - val_classification_output_loss: 2.0741 - val_classification_output_accuracy: 0.2399\n",
            "Epoch 11/200\n",
            "391/391 [==============================] - 26s 66ms/step - loss: 0.8971 - restoration_output_loss: 0.5661 - classification_output_loss: 2.1887 - classification_output_accuracy: 0.2121 - val_loss: 0.8724 - val_restoration_output_loss: 0.5664 - val_classification_output_loss: 2.0644 - val_classification_output_accuracy: 0.2513\n",
            "Epoch 12/200\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 0.8965 - restoration_output_loss: 0.5649 - classification_output_loss: 2.1916 - classification_output_accuracy: 0.2135 - val_loss: 0.8716 - val_restoration_output_loss: 0.5657 - val_classification_output_loss: 2.0640 - val_classification_output_accuracy: 0.2561\n",
            "Epoch 13/200\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 0.8960 - restoration_output_loss: 0.5638 - classification_output_loss: 2.1939 - classification_output_accuracy: 0.2148 - val_loss: 0.8739 - val_restoration_output_loss: 0.5669 - val_classification_output_loss: 2.0714 - val_classification_output_accuracy: 0.2503\n",
            "Epoch 14/200\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 0.8942 - restoration_output_loss: 0.5630 - classification_output_loss: 2.1889 - classification_output_accuracy: 0.2149 - val_loss: 0.8729 - val_restoration_output_loss: 0.5627 - val_classification_output_loss: 2.0837 - val_classification_output_accuracy: 0.2462\n",
            "Epoch 15/200\n",
            "391/391 [==============================] - 24s 60ms/step - loss: 0.8955 - restoration_output_loss: 0.5624 - classification_output_loss: 2.1981 - classification_output_accuracy: 0.2176 - val_loss: 0.8667 - val_restoration_output_loss: 0.5639 - val_classification_output_loss: 2.0487 - val_classification_output_accuracy: 0.2606\n",
            "Epoch 16/200\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 0.8945 - restoration_output_loss: 0.5616 - classification_output_loss: 2.1969 - classification_output_accuracy: 0.2163 - val_loss: 0.8653 - val_restoration_output_loss: 0.5608 - val_classification_output_loss: 2.0543 - val_classification_output_accuracy: 0.2558\n",
            "Epoch 17/200\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 0.8958 - restoration_output_loss: 0.5619 - classification_output_loss: 2.2025 - classification_output_accuracy: 0.2217 - val_loss: 0.8667 - val_restoration_output_loss: 0.5633 - val_classification_output_loss: 2.0516 - val_classification_output_accuracy: 0.2615\n",
            "Epoch 18/200\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 0.8953 - restoration_output_loss: 0.5599 - classification_output_loss: 2.2084 - classification_output_accuracy: 0.2188 - val_loss: 0.8635 - val_restoration_output_loss: 0.5609 - val_classification_output_loss: 2.0453 - val_classification_output_accuracy: 0.2632\n",
            "Epoch 19/200\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 0.8977 - restoration_output_loss: 0.5608 - classification_output_loss: 2.2169 - classification_output_accuracy: 0.2216 - val_loss: 0.8668 - val_restoration_output_loss: 0.5634 - val_classification_output_loss: 2.0524 - val_classification_output_accuracy: 0.2530\n",
            "Epoch 20/200\n",
            "391/391 [==============================] - 24s 60ms/step - loss: 0.8977 - restoration_output_loss: 0.5599 - classification_output_loss: 2.2210 - classification_output_accuracy: 0.2183 - val_loss: 0.8645 - val_restoration_output_loss: 0.5598 - val_classification_output_loss: 2.0557 - val_classification_output_accuracy: 0.2590\n",
            "Epoch 21/200\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 0.8953 - restoration_output_loss: 0.5590 - classification_output_loss: 2.2130 - classification_output_accuracy: 0.2215 - val_loss: 0.8666 - val_restoration_output_loss: 0.5604 - val_classification_output_loss: 2.0641 - val_classification_output_accuracy: 0.2545\n",
            "Epoch 22/200\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.8950 - restoration_output_loss: 0.5586 - classification_output_loss: 2.2135 - classification_output_accuracy: 0.2228 - val_loss: 0.8638 - val_restoration_output_loss: 0.5590 - val_classification_output_loss: 2.0559 - val_classification_output_accuracy: 0.2591\n",
            "Epoch 23/200\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.8962 - restoration_output_loss: 0.5589 - classification_output_loss: 2.2186 - classification_output_accuracy: 0.2221 - val_loss: 0.8624 - val_restoration_output_loss: 0.5592 - val_classification_output_loss: 2.0481 - val_classification_output_accuracy: 0.2530\n",
            "Epoch 24/200\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.8943 - restoration_output_loss: 0.5577 - classification_output_loss: 2.2135 - classification_output_accuracy: 0.2264 - val_loss: 0.8603 - val_restoration_output_loss: 0.5565 - val_classification_output_loss: 2.0487 - val_classification_output_accuracy: 0.2582\n",
            "Epoch 25/200\n",
            "391/391 [==============================] - 26s 67ms/step - loss: 0.8961 - restoration_output_loss: 0.5579 - classification_output_loss: 2.2221 - classification_output_accuracy: 0.2253 - val_loss: 0.8663 - val_restoration_output_loss: 0.5619 - val_classification_output_loss: 2.0571 - val_classification_output_accuracy: 0.2608\n",
            "Epoch 26/200\n",
            "391/391 [==============================] - 22s 57ms/step - loss: 0.8959 - restoration_output_loss: 0.5568 - classification_output_loss: 2.2255 - classification_output_accuracy: 0.2240 - val_loss: 0.8627 - val_restoration_output_loss: 0.5596 - val_classification_output_loss: 2.0489 - val_classification_output_accuracy: 0.2640\n",
            "Epoch 27/200\n",
            "391/391 [==============================] - 22s 56ms/step - loss: 0.8953 - restoration_output_loss: 0.5576 - classification_output_loss: 2.2193 - classification_output_accuracy: 0.2261 - val_loss: 0.8590 - val_restoration_output_loss: 0.5571 - val_classification_output_loss: 2.0405 - val_classification_output_accuracy: 0.2624\n",
            "Epoch 28/200\n",
            "391/391 [==============================] - 22s 56ms/step - loss: 0.8978 - restoration_output_loss: 0.5576 - classification_output_loss: 2.2323 - classification_output_accuracy: 0.2247 - val_loss: 0.8600 - val_restoration_output_loss: 0.5565 - val_classification_output_loss: 2.0482 - val_classification_output_accuracy: 0.2606\n",
            "Epoch 29/200\n",
            "391/391 [==============================] - 22s 56ms/step - loss: 0.8984 - restoration_output_loss: 0.5574 - classification_output_loss: 2.2362 - classification_output_accuracy: 0.2258 - val_loss: 0.8598 - val_restoration_output_loss: 0.5574 - val_classification_output_loss: 2.0435 - val_classification_output_accuracy: 0.2588\n",
            "Epoch 30/200\n",
            "391/391 [==============================] - 22s 56ms/step - loss: 0.8975 - restoration_output_loss: 0.5580 - classification_output_loss: 2.2297 - classification_output_accuracy: 0.2233 - val_loss: 0.8642 - val_restoration_output_loss: 0.5604 - val_classification_output_loss: 2.0535 - val_classification_output_accuracy: 0.2615\n",
            "Epoch 31/200\n",
            "391/391 [==============================] - 22s 56ms/step - loss: 0.8974 - restoration_output_loss: 0.5574 - classification_output_loss: 2.2315 - classification_output_accuracy: 0.2262 - val_loss: 0.8543 - val_restoration_output_loss: 0.5536 - val_classification_output_loss: 2.0315 - val_classification_output_accuracy: 0.2683\n",
            "Epoch 32/200\n",
            "391/391 [==============================] - 22s 56ms/step - loss: 0.8953 - restoration_output_loss: 0.5551 - classification_output_loss: 2.2304 - classification_output_accuracy: 0.2267 - val_loss: 0.8554 - val_restoration_output_loss: 0.5533 - val_classification_output_loss: 2.0380 - val_classification_output_accuracy: 0.2690\n",
            "Epoch 33/200\n",
            "391/391 [==============================] - 22s 55ms/step - loss: 0.8973 - restoration_output_loss: 0.5566 - classification_output_loss: 2.2345 - classification_output_accuracy: 0.2246 - val_loss: 0.8570 - val_restoration_output_loss: 0.5548 - val_classification_output_loss: 2.0404 - val_classification_output_accuracy: 0.2641\n",
            "Epoch 34/200\n",
            "391/391 [==============================] - 22s 55ms/step - loss: 0.8978 - restoration_output_loss: 0.5564 - classification_output_loss: 2.2381 - classification_output_accuracy: 0.2219 - val_loss: 0.8582 - val_restoration_output_loss: 0.5566 - val_classification_output_loss: 2.0390 - val_classification_output_accuracy: 0.2639\n",
            "Epoch 35/200\n",
            "391/391 [==============================] - 22s 56ms/step - loss: 0.8969 - restoration_output_loss: 0.5563 - classification_output_loss: 2.2336 - classification_output_accuracy: 0.2281 - val_loss: 0.8600 - val_restoration_output_loss: 0.5587 - val_classification_output_loss: 2.0402 - val_classification_output_accuracy: 0.2698\n",
            "Epoch 36/200\n",
            "391/391 [==============================] - 24s 62ms/step - loss: 0.8984 - restoration_output_loss: 0.5564 - classification_output_loss: 2.2408 - classification_output_accuracy: 0.2247 - val_loss: 0.8584 - val_restoration_output_loss: 0.5576 - val_classification_output_loss: 2.0363 - val_classification_output_accuracy: 0.2630\n",
            "Epoch 37/200\n",
            "391/391 [==============================] - 22s 57ms/step - loss: 0.8988 - restoration_output_loss: 0.5564 - classification_output_loss: 2.2432 - classification_output_accuracy: 0.2241 - val_loss: 0.8593 - val_restoration_output_loss: 0.5554 - val_classification_output_loss: 2.0497 - val_classification_output_accuracy: 0.2660\n",
            "Epoch 38/200\n",
            "391/391 [==============================] - 22s 56ms/step - loss: 0.8993 - restoration_output_loss: 0.5567 - classification_output_loss: 2.2445 - classification_output_accuracy: 0.2235 - val_loss: 0.8607 - val_restoration_output_loss: 0.5559 - val_classification_output_loss: 2.0548 - val_classification_output_accuracy: 0.2621\n",
            "Epoch 39/200\n",
            "391/391 [==============================] - 22s 56ms/step - loss: 0.8980 - restoration_output_loss: 0.5563 - classification_output_loss: 2.2397 - classification_output_accuracy: 0.2257 - val_loss: 0.8600 - val_restoration_output_loss: 0.5559 - val_classification_output_loss: 2.0516 - val_classification_output_accuracy: 0.2634\n",
            "Epoch 40/200\n",
            "391/391 [==============================] - 22s 56ms/step - loss: 0.8964 - restoration_output_loss: 0.5546 - classification_output_loss: 2.2388 - classification_output_accuracy: 0.2274 - val_loss: 0.8546 - val_restoration_output_loss: 0.5526 - val_classification_output_loss: 2.0375 - val_classification_output_accuracy: 0.2657\n",
            "Epoch 41/200\n",
            "391/391 [==============================] - 22s 56ms/step - loss: 0.9004 - restoration_output_loss: 0.5557 - classification_output_loss: 2.2545 - classification_output_accuracy: 0.2220 - val_loss: 0.8551 - val_restoration_output_loss: 0.5548 - val_classification_output_loss: 2.0312 - val_classification_output_accuracy: 0.2694\n",
            "Epoch 42/200\n",
            "391/391 [==============================] - 22s 56ms/step - loss: 0.9004 - restoration_output_loss: 0.5561 - classification_output_loss: 2.2528 - classification_output_accuracy: 0.2247 - val_loss: 0.8601 - val_restoration_output_loss: 0.5568 - val_classification_output_loss: 2.0484 - val_classification_output_accuracy: 0.2666\n",
            "Epoch 43/200\n",
            "391/391 [==============================] - 22s 56ms/step - loss: 0.8996 - restoration_output_loss: 0.5557 - classification_output_loss: 2.2504 - classification_output_accuracy: 0.2237 - val_loss: 0.8572 - val_restoration_output_loss: 0.5569 - val_classification_output_loss: 2.0334 - val_classification_output_accuracy: 0.2676\n",
            "Epoch 44/200\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.9014 - restoration_output_loss: 0.5549 - classification_output_loss: 2.2625 - classification_output_accuracy: 0.2212 - val_loss: 0.8605 - val_restoration_output_loss: 0.5575 - val_classification_output_loss: 2.0480 - val_classification_output_accuracy: 0.2625\n",
            "Epoch 45/200\n",
            "391/391 [==============================] - 22s 56ms/step - loss: 0.9000 - restoration_output_loss: 0.5551 - classification_output_loss: 2.2550 - classification_output_accuracy: 0.2222 - val_loss: 0.8557 - val_restoration_output_loss: 0.5544 - val_classification_output_loss: 2.0361 - val_classification_output_accuracy: 0.2651\n",
            "Epoch 46/200\n",
            "391/391 [==============================] - 22s 56ms/step - loss: 0.8999 - restoration_output_loss: 0.5553 - classification_output_loss: 2.2540 - classification_output_accuracy: 0.2220 - val_loss: 0.8560 - val_restoration_output_loss: 0.5538 - val_classification_output_loss: 2.0406 - val_classification_output_accuracy: 0.2608\n",
            "Epoch 47/200\n",
            "391/391 [==============================] - 22s 56ms/step - loss: 0.9023 - restoration_output_loss: 0.5555 - classification_output_loss: 2.2651 - classification_output_accuracy: 0.2219 - val_loss: 0.8582 - val_restoration_output_loss: 0.5556 - val_classification_output_loss: 2.0443 - val_classification_output_accuracy: 0.2626\n",
            "Epoch 48/200\n",
            "391/391 [==============================] - 22s 56ms/step - loss: 0.9002 - restoration_output_loss: 0.5551 - classification_output_loss: 2.2560 - classification_output_accuracy: 0.2262 - val_loss: 0.8622 - val_restoration_output_loss: 0.5559 - val_classification_output_loss: 2.0628 - val_classification_output_accuracy: 0.2608\n",
            "Epoch 49/200\n",
            "391/391 [==============================] - 22s 56ms/step - loss: 0.9019 - restoration_output_loss: 0.5550 - classification_output_loss: 2.2648 - classification_output_accuracy: 0.2233 - val_loss: 0.8578 - val_restoration_output_loss: 0.5559 - val_classification_output_loss: 2.0412 - val_classification_output_accuracy: 0.2621\n",
            "Epoch 50/200\n",
            "391/391 [==============================] - 22s 56ms/step - loss: 0.8996 - restoration_output_loss: 0.5550 - classification_output_loss: 2.2537 - classification_output_accuracy: 0.2220 - val_loss: 0.8558 - val_restoration_output_loss: 0.5550 - val_classification_output_loss: 2.0348 - val_classification_output_accuracy: 0.2694\n",
            "Epoch 51/200\n",
            "391/391 [==============================] - 22s 56ms/step - loss: 0.9007 - restoration_output_loss: 0.5548 - classification_output_loss: 2.2598 - classification_output_accuracy: 0.2208 - val_loss: 0.8564 - val_restoration_output_loss: 0.5546 - val_classification_output_loss: 2.0392 - val_classification_output_accuracy: 0.2639\n",
            "Epoch 52/200\n",
            "391/391 [==============================] - 25s 64ms/step - loss: 0.9000 - restoration_output_loss: 0.5542 - classification_output_loss: 2.2586 - classification_output_accuracy: 0.2255 - val_loss: 0.8568 - val_restoration_output_loss: 0.5552 - val_classification_output_loss: 2.0390 - val_classification_output_accuracy: 0.2645\n",
            "Epoch 53/200\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.9012 - restoration_output_loss: 0.5548 - classification_output_loss: 2.2625 - classification_output_accuracy: 0.2231 - val_loss: 0.8600 - val_restoration_output_loss: 0.5556 - val_classification_output_loss: 2.0537 - val_classification_output_accuracy: 0.2645\n",
            "Epoch 54/200\n",
            "391/391 [==============================] - 26s 66ms/step - loss: 0.9019 - restoration_output_loss: 0.5542 - classification_output_loss: 2.2684 - classification_output_accuracy: 0.2200 - val_loss: 0.8591 - val_restoration_output_loss: 0.5558 - val_classification_output_loss: 2.0480 - val_classification_output_accuracy: 0.2616\n",
            "Epoch 55/200\n",
            "391/391 [==============================] - 26s 65ms/step - loss: 0.9018 - restoration_output_loss: 0.5554 - classification_output_loss: 2.2633 - classification_output_accuracy: 0.2204 - val_loss: 0.8590 - val_restoration_output_loss: 0.5531 - val_classification_output_loss: 2.0584 - val_classification_output_accuracy: 0.2633\n",
            "\n",
            "Training DnCNN (up to 200 epochs, early-stop) ...\n",
            "Epoch 1/200\n"
          ]
        }
      ],
      "source": [
        "# Train/Load CAE MTL only, then evaluate SER (Gaussian)\n",
        "EPOCHS = 200\n",
        "ckpt_dir = '/Users/ihaegwon/Lab'\n",
        "cae_ckpt = os.path.join(ckpt_dir, 'best_cae_multitask.keras')\n",
        "\n",
        "callbacks_cae = [\n",
        "    EarlyStopping(monitor='val_classification_output_accuracy', patience=20, restore_best_weights=True),\n",
        "    ModelCheckpoint(filepath=cae_ckpt, save_weights_only=False, monitor='val_classification_output_accuracy', mode='max', save_best_only=True)\n",
        "]\n",
        "\n",
        "if os.path.exists(cae_ckpt):\n",
        "    print(f'Loading CAE weights from {cae_ckpt}')\n",
        "    cae_model = tf.keras.models.load_model(cae_ckpt)\n",
        "else:\n",
        "    print('\\nTraining CAE (up to 200 epochs, early-stop) ...')\n",
        "    cae_model.fit(train_ds_mixed, epochs=EPOCHS, validation_data=val_ds_mixed, callbacks=callbacks_cae, verbose=1)\n",
        "\n",
        "cae_ser = eval_model_ser_over_snrs(cae_model, x_test, y_test, snr_grid, noise_type='gaussian', batch_size=512)\n",
        "\n",
        "models_map = {'UNet (MTL)': unet_ser, 'CAE (MTL)': cae_ser}\n",
        "plot_snr_ser(models_map, title='Gaussian: SNR vs SER (UNet vs CAE)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fixed classifier (clean CIFAR-10) with load-if-exists\n",
        "\n",
        "def build_fixed_classifier(input_shape=(32,32,3), num_classes=10):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(32, 3, padding='same', activation='relu')(inputs)\n",
        "    x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
        "    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "    return Model(inputs, outputs, name='FixedClassifier')\n",
        "\n",
        "clf_ckpt = '/Users/ihaegwon/Lab/best_fixed_classifier.keras'\n",
        "if os.path.exists(clf_ckpt):\n",
        "    print(f'Loading fixed classifier from {clf_ckpt}')\n",
        "    fixed_clf = tf.keras.models.load_model(clf_ckpt)\n",
        "else:\n",
        "    fixed_clf = build_fixed_classifier()\n",
        "    fixed_clf.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "    clf_callbacks = [\n",
        "        EarlyStopping(monitor='val_accuracy', patience=8, restore_best_weights=True),\n",
        "        ModelCheckpoint(filepath=clf_ckpt, save_weights_only=False, monitor='val_accuracy', mode='max', save_best_only=True)\n",
        "    ]\n",
        "    print('\\nTraining fixed classifier on clean CIFAR-10 ...')\n",
        "    fixed_clf.fit(x_train, y_train, validation_data=(x_test, y_test),\n",
        "                  epochs=50, batch_size=256, callbacks=clf_callbacks, verbose=1)\n",
        "    print('Saved best fixed classifier to', clf_ckpt)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic restoration-only CAE/DnCNN (no conditioning, no classifier head)\n",
        "\n",
        "def build_cae_restoration(input_shape=(32,32,3)):\n",
        "    inp = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(32,3,padding='same',activation='relu')(inp)\n",
        "    x = layers.Conv2D(32,3,padding='same',activation='relu')(x)\n",
        "    s1 = x\n",
        "    p1 = layers.MaxPooling2D(2)(x)\n",
        "    x = layers.Conv2D(64,3,padding='same',activation='relu')(p1)\n",
        "    x = layers.Conv2D(64,3,padding='same',activation='relu')(x)\n",
        "    s2 = x\n",
        "    p2 = layers.MaxPooling2D(2)(x)\n",
        "    x = layers.Conv2D(128,3,padding='same',activation='relu')(p2)\n",
        "    x = layers.Conv2D(128,3,padding='same',activation='relu')(x)\n",
        "    d = layers.Conv2DTranspose(64,2,strides=2,padding='same')(x)\n",
        "    d = layers.Concatenate()([d, s2])\n",
        "    d = layers.Conv2D(64,3,padding='same',activation='relu')(d)\n",
        "    d = layers.Conv2D(64,3,padding='same',activation='relu')(d)\n",
        "    d = layers.Conv2DTranspose(32,2,strides=2,padding='same')(d)\n",
        "    d = layers.Concatenate()([d, s1])\n",
        "    d = layers.Conv2D(32,3,padding='same',activation='relu')(d)\n",
        "    d = layers.Conv2D(32,3,padding='same',activation='relu')(d)\n",
        "    out = layers.Conv2D(3,1,activation='linear')(d)\n",
        "    return Model(inp, out, name='CAE_restoration')\n",
        "\n",
        "\n",
        "def build_dncnn_restoration(input_shape=(32,32,3), depth=17, filters=64):\n",
        "    inp = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(filters,3,padding='same',activation='relu')(inp)\n",
        "    for _ in range(depth-2):\n",
        "        x = layers.Conv2D(filters,3,padding='same',use_bias=False)(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation('relu')(x)\n",
        "    res = layers.Conv2D(3,3,padding='same',activation='linear')(x)\n",
        "    out = layers.Subtract()([inp, res])\n",
        "    return Model(inp, out, name='DnCNN_restoration')\n",
        "\n",
        "cae_rest_ckpt = '/Users/ihaegwon/Lab/best_cae_restoration.keras'\n",
        "dncnn_rest_ckpt = '/Users/ihaegwon/Lab/best_dncnn_restoration.keras'\n",
        "\n",
        "cae_rest = build_cae_restoration(); dncnn_rest = build_dncnn_restoration()\n",
        "for m in [cae_rest, dncnn_rest]:\n",
        "    m.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss='mae')\n",
        "\n",
        "# Train or load restoration-only models using mixed Gaussian SNR data\n",
        "rest_train = train_ds_mixed.map(lambda inp, tgt: (from_zscore(inp[0]), from_zscore(tgt[0])))\n",
        "rest_val   = val_ds_mixed.map(lambda inp, tgt: (from_zscore(inp[0]), from_zscore(tgt[0])))\n",
        "\n",
        "rest_callbacks_cae = [EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                      ModelCheckpoint(filepath=cae_rest_ckpt, save_weights_only=False, monitor='val_loss', mode='min', save_best_only=True)]\n",
        "rest_callbacks_dn  = [EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                      ModelCheckpoint(filepath=dncnn_rest_ckpt, save_weights_only=False, monitor='val_loss', mode='min', save_best_only=True)]\n",
        "\n",
        "if os.path.exists(cae_rest_ckpt):\n",
        "    print(f'Loading CAE restoration from {cae_rest_ckpt}')\n",
        "    cae_rest = tf.keras.models.load_model(cae_rest_ckpt)\n",
        "else:\n",
        "    print('\\nTraining CAE restoration ...')\n",
        "    cae_rest.fit(rest_train, validation_data=rest_val, epochs=100, callbacks=rest_callbacks_cae, verbose=1)\n",
        "\n",
        "if os.path.exists(dncnn_rest_ckpt):\n",
        "    print(f'Loading DnCNN restoration from {dncnn_rest_ckpt}')\n",
        "    dncnn_rest = tf.keras.models.load_model(dncnn_rest_ckpt)\n",
        "else:\n",
        "    print('\\nTraining DnCNN restoration ...')\n",
        "    dncnn_rest.fit(rest_train, validation_data=rest_val, epochs=100, callbacks=rest_callbacks_dn, verbose=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pipeline SER evaluators (no-rest and restoration+classifier)\n",
        "\n",
        "def eval_pipeline_ser_over_snrs(classifier, restorer, x, y, snr_list_db, noise_type='gaussian', batch_size=512):\n",
        "    results = {}\n",
        "    for snr in snr_list_db:\n",
        "        ds = make_fixed_snr_dataset_noise(x, y, snr_db=float(snr), noise_type=noise_type, batch_size=batch_size)\n",
        "        total = 0; errors = 0\n",
        "        for (noisy_z_b, cond_b), (clean_z_b, label_b) in ds:\n",
        "            if restorer is None:\n",
        "                restored = from_zscore(noisy_z_b)\n",
        "            else:\n",
        "                restored = restorer.predict(from_zscore(noisy_z_b), verbose=0)\n",
        "            logits_b = classifier.predict(restored, verbose=0)\n",
        "            pred = np.argmax(logits_b, axis=-1)\n",
        "            total += label_b.shape[0]\n",
        "            errors += int(np.sum(pred != label_b.numpy()))\n",
        "        results[float(snr)] = errors / max(1, total)\n",
        "    return results\n",
        "\n",
        "snr_grid = list(range(-30, -9, 2))\n",
        "\n",
        "# Evaluate pipeline baselines (Gaussian)\n",
        "no_rest_ser  = eval_pipeline_ser_over_snrs(fixed_clf, None,       x_test, y_test, snr_grid, noise_type='gaussian', batch_size=512)\n",
        "cae_pipe_ser = eval_pipeline_ser_over_snrs(fixed_clf, cae_rest,   x_test, y_test, snr_grid, noise_type='gaussian', batch_size=512)\n",
        "dn_pipe_ser  = eval_pipeline_ser_over_snrs(fixed_clf, dncnn_rest, x_test, y_test, snr_grid, noise_type='gaussian', batch_size=512)\n",
        "\n",
        "# Combine plots with MTL models already computed in previous cell\n",
        "models_map = {\n",
        "    'UNet (MTL)': unet_ser,\n",
        "    'CAE (MTL)': cae_ser,\n",
        "    'DnCNN (MTL)': dncnn_ser,\n",
        "    'No-Rest + FixedClf': no_rest_ser,\n",
        "    'CAE-Rest + FixedClf': cae_pipe_ser,\n",
        "    'DnCNN-Rest + FixedClf': dn_pipe_ser,   \n",
        "}\n",
        "plot_snr_ser(models_map, title='Gaussian: SNR vs SER (MTL vs Pipelines)')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/Load DnCNN MTL separately, then evaluate SER (Gaussian)\n",
        "EPOCHS = 200\n",
        "ckpt_dir = '/Users/ihaegwon/Lab'\n",
        "dncnn_ckpt = os.path.join(ckpt_dir, 'best_dncnn_multitask.keras')\n",
        "\n",
        "callbacks_dncnn = [\n",
        "    EarlyStopping(monitor='val_classification_output_accuracy', patience=20, restore_best_weights=True),\n",
        "    ModelCheckpoint(filepath=dncnn_ckpt, save_weights_only=False, monitor='val_classification_output_accuracy', mode='max', save_best_only=True)\n",
        "]\n",
        "\n",
        "if os.path.exists(dncnn_ckpt):\n",
        "    print(f'Loading DnCNN weights from {dncnn_ckpt}')\n",
        "    dncnn_model = tf.keras.models.load_model(dncnn_ckpt)\n",
        "else:\n",
        "    print('\\nTraining DnCNN (up to 200 epochs, early-stop) ...')\n",
        "    dncnn_model.fit(train_ds_mixed, epochs=EPOCHS, validation_data=val_ds_mixed, callbacks=callbacks_dncnn, verbose=1)\n",
        "\n",
        "try:\n",
        "    dncnn_ser = eval_model_ser_over_snrs(dncnn_model, x_test, y_test, snr_grid, noise_type='gaussian', batch_size=512)\n",
        "    models_map = {'UNet (MTL)': unet_ser}\n",
        "    if 'cae_ser' in globals(): models_map['CAE (MTL)'] = cae_ser\n",
        "    models_map['DnCNN (MTL)'] = dncnn_ser\n",
        "    plot_snr_ser(models_map, title='Gaussian: SNR vs SER (UNet vs CAE vs DnCNN)')\n",
        "except Exception as e:\n",
        "    print('DnCNN evaluation skipped due to error:', e)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tf-final",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
